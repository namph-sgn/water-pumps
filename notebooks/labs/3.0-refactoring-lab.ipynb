{"nbformat":4,"nbformat_minor":0,"cells":[{"source":["<table style=\"width:100%; border: 0px solid black;\">\n","    <tr style=\"width: 100%; border: 0px solid black;\">\n","        <td style=\"width:75%; border: 0px solid black;\">\n","            <a href=\"http://www.drivendata.org\">\n","                <img src=\"https://s3.amazonaws.com/drivendata.org/kif-example/img/dd.png\" />\n","            </a>\n","        </td>\n","    </tr>\n","</table>\n","\n","# Data Science is Software\n","---------\n","## Developer #lifehacks for the Jupyter Data Scientist\n","\n","### Section 3:  Refactoring for reusability"],"cell_type":"markdown","metadata":{}},{"outputs":[],"source":["%matplotlib inline\n","from __future__ import print_function\n","\n","import os\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","PROJ_ROOT = os.path.join(os.pardir, os.pardir)\n","# Add project src to environment data path\n","import sys\n","src_dir = os.path.join(PROJ_ROOT, 'src')\n","sys.path.append(src_dir)"],"execution_count":54,"cell_type":"code","metadata":{"collapsed":true}},{"source":["## Use debugging tools throughout!\n","\n","Don't forget all the fun debugging tools we covered while you work on these exercises. \n","\n"," - `%debug`\n"," - `%pdb`\n"," - `import q;q.d()`\n"," - And (if necessary) `%prun`\n","\n","\n","## Exercise 1\n","\n","You'll notice that our dataset actually has two different files, `pumps_train_values.csv` and `pumps_train_labels.csv`. We want to load both of these together in a single `DataFrame` for our exploratory analysis. Create a function that:\n"," - Reads both of the csvs\n"," - uses the `id` column as the index\n"," - parses dates of the `date_recorded` columns\n"," - joins the labels and the training set on the id\n"," - returns the complete dataframe"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id    status_group\n","0      69572      functional\n","1       8776      functional\n","2      34310      functional\n","3      67743  non functional\n","4      19728      functional\n","...      ...             ...\n","59395  60739      functional\n","59396  27263      functional\n","59397  37057      functional\n","59398  31282      functional\n","59399  26348      functional\n","\n","[59400 rows x 2 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>status_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69572</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8776</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34310</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67743</td>\n      <td>non functional</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19728</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59395</th>\n      <td>60739</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>59396</th>\n      <td>27263</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>59397</th>\n      <td>37057</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>59398</th>\n      <td>31282</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>59399</th>\n      <td>26348</td>\n      <td>functional</td>\n    </tr>\n  </tbody>\n</table>\n<p>59400 rows Ã— 2 columns</p>\n</div>"},"metadata":{},"execution_count":23}],"source":["df_labels"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"output_type":"stream","text":["\u001b[0;31mSignature:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDocstring:\u001b[0m\n","Join columns of another DataFrame.\n","\n","Join columns with `other` DataFrame either on index or on a key\n","column. Efficiently join multiple DataFrame objects by index at once by\n","passing a list.\n","\n","Parameters\n","----------\n","other : DataFrame, Series, or list of DataFrame\n","    Index should be similar to one of the columns in this one. If a\n","    Series is passed, its name attribute must be set, and that will be\n","    used as the column name in the resulting joined DataFrame.\n","on : str, list of str, or array-like, optional\n","    Column or index level name(s) in the caller to join on the index\n","    in `other`, otherwise joins index-on-index. If multiple\n","    values given, the `other` DataFrame must have a MultiIndex. Can\n","    pass an array as the join key if it is not already contained in\n","    the calling DataFrame. Like an Excel VLOOKUP operation.\n","how : {'left', 'right', 'outer', 'inner'}, default 'left'\n","    How to handle the operation of the two objects.\n","\n","    * left: use calling frame's index (or column if on is specified)\n","    * right: use `other`'s index.\n","    * outer: form union of calling frame's index (or column if on is\n","      specified) with `other`'s index, and sort it.\n","      lexicographically.\n","    * inner: form intersection of calling frame's index (or column if\n","      on is specified) with `other`'s index, preserving the order\n","      of the calling's one.\n","lsuffix : str, default ''\n","    Suffix to use from left frame's overlapping columns.\n","rsuffix : str, default ''\n","    Suffix to use from right frame's overlapping columns.\n","sort : bool, default False\n","    Order result DataFrame lexicographically by the join key. If False,\n","    the order of the join key depends on the join type (how keyword).\n","\n","Returns\n","-------\n","DataFrame\n","    A dataframe containing columns from both the caller and `other`.\n","\n","See Also\n","--------\n","DataFrame.merge : For column(s)-on-column(s) operations.\n","\n","Notes\n","-----\n","Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n","passing a list of `DataFrame` objects.\n","\n","Support for specifying index levels as the `on` parameter was added\n","in version 0.23.0.\n","\n","Examples\n","--------\n",">>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n","...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n","\n",">>> df\n","  key   A\n","0  K0  A0\n","1  K1  A1\n","2  K2  A2\n","3  K3  A3\n","4  K4  A4\n","5  K5  A5\n","\n",">>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n","...                       'B': ['B0', 'B1', 'B2']})\n","\n",">>> other\n","  key   B\n","0  K0  B0\n","1  K1  B1\n","2  K2  B2\n","\n","Join DataFrames using their indexes.\n","\n",">>> df.join(other, lsuffix='_caller', rsuffix='_other')\n","  key_caller   A key_other    B\n","0         K0  A0        K0   B0\n","1         K1  A1        K1   B1\n","2         K2  A2        K2   B2\n","3         K3  A3       NaN  NaN\n","4         K4  A4       NaN  NaN\n","5         K5  A5       NaN  NaN\n","\n","If we want to join using the key columns, we need to set key to be\n","the index in both `df` and `other`. The joined DataFrame will have\n","key as its index.\n","\n",">>> df.set_index('key').join(other.set_index('key'))\n","      A    B\n","key\n","K0   A0   B0\n","K1   A1   B1\n","K2   A2   B2\n","K3   A3  NaN\n","K4   A4  NaN\n","K5   A5  NaN\n","\n","Another option to join using the key columns is to use the `on`\n","parameter. DataFrame.join always uses `other`'s index but we can use\n","any column in `df`. This method preserves the original DataFrame's\n","index in the result.\n","\n",">>> df.join(other.set_index('key'), on='key')\n","  key   A    B\n","0  K0  A0   B0\n","1  K1  A1   B1\n","2  K2  A2   B2\n","3  K3  A3  NaN\n","4  K4  A4  NaN\n","5  K5  A5  NaN\n","\u001b[0;31mFile:\u001b[0m      ~/Development/anaconda3/envs/water-pumps/lib/python3.9/site-packages/pandas/core/frame.py\n","\u001b[0;31mType:\u001b[0m      method\n"],"name":"stdout"}],"source":["df.join?"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n","       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n","       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n","       'ward', 'population', 'public_meeting', 'recorded_by',\n","       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n","       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n","       'management', 'management_group', 'payment', 'payment_type',\n","       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n","       'source', 'source_type', 'source_class', 'waterpoint_type',\n","       'waterpoint_type_group', 'status_group'],\n","      dtype='object')"]},"metadata":{},"execution_count":34}],"source":["df.columns"]},{"outputs":[],"source":["def load_pumps_data(values_path, labels_path):\n","    df = pd.read_csv(values_path)\n","    df_labels = pd.read_csv(labels_path)\n","    df = df.join(df_labels.set_index('id'), on='id', how='left')\n","    return df\n","    \n","    \n","values = os.path.join(PROJ_ROOT, \"data\", \"raw\", \"pumps_train_values.csv\")\n","labels = os.path.join(PROJ_ROOT, \"data\", \"raw\", \"pumps_train_labels.csv\")\n","\n","df = load_pumps_data(values, labels)\n","assert df.shape == (59400, 41)"],"execution_count":56,"cell_type":"code","metadata":{"collapsed":false}},{"source":["## Exercise 2\n","\n","Now that we've loaded our data, we want to do some pre-processing before we model. From inspection of the data, we've noticed that there are some numeric values that are probably not valid that we want to replace.\n","\n"," - Select the relevant columns for modeling. For the purposes of this exercise, we'll select:\n","        useful_columns = ['amount_tsh',\n","                      'gps_height',\n","                      'longitude',\n","                      'latitude',\n","                      'region',\n","                      'population',\n","                      'construction_year',\n","                      'extraction_type_class',\n","                      'management_group',\n","                      'quality_group',\n","                      'source_type',\n","                      'waterpoint_type',\n","                      'status_group']\n","\n"," - Replace longitude, and population where it is 0 with mean for that region.\n","       zero_is_bad_value = ['longitude', 'population']\n","       \n"," - Replace the latitude where it is -2E-8 (a different bad value) with the mean for that region.\n","       other_bad_value = ['latitude']\n","      \n"," - Replace construction_year less than 1000 with the mean construction year.\n"," - Convert object type (i.e., string) variables to categoricals.\n"," - Convert the label column into a categorical variable\n"," \n","\n","A skeleton for this work is below where `clean_raw_data` will call `replace_value_with_grouped_mean` internally. \n","\n","**Copy and Paste the skeleton below into a Python file called `preprocess.py` in `src/features/`. Import and autoload the methods from that file to run tests on your changes in this notebook.**"],"cell_type":"markdown","metadata":{}},{"outputs":[],"source":["def clean_raw_data(df):\n","    \"\"\" Takes a dataframe and performs four steps:\n","            - Selects columns for modeling\n","            - For numeric variables, replaces 0 values with mean for that region\n","            - Fills invalid construction_year values with the mean construction_year\n","            - Converts strings to categorical variables\n","            \n","        :param df: A raw dataframe that has been read into pandas\n","        :returns: A dataframe with the preprocessing performed.\n","    \"\"\"\n","    \n","    pass\n","    \n","def replace_value_with_grouped_mean(df, value, column, to_groupby):\n","    \"\"\" For a given numeric value (e.g., 0) in a particular column, take the\n","        mean of column (excluding value) grouped by to_groupby and return that\n","        column with the value replaced by that mean.\n","\n","        :param df: The dataframe to operate on.\n","        :param value: The value in column that should be replaced.\n","        :param column: The column in which replacements need to be made.\n","        :param to_groupby: Groupby this variable and take the mean of column.\n","                           Replace value with the group's mean.\n","        :returns: The data frame with the invalid values replaced\n","    \"\"\"\n","    pass\n"],"execution_count":null,"cell_type":"code","metadata":{"collapsed":false,"scrolled":false}},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                         int64\n","amount_tsh               float64\n","date_recorded             object\n","funder                    object\n","gps_height                 int64\n","installer                 object\n","longitude                float64\n","latitude                 float64\n","wpt_name                  object\n","num_private                int64\n","basin                     object\n","subvillage                object\n","region                    object\n","region_code                int64\n","district_code              int64\n","lga                       object\n","ward                      object\n","population                 int64\n","public_meeting            object\n","recorded_by               object\n","scheme_management         object\n","scheme_name               object\n","permit                    object\n","construction_year          int64\n","extraction_type           object\n","extraction_type_group     object\n","extraction_type_class     object\n","management                object\n","management_group          object\n","payment                   object\n","payment_type              object\n","water_quality             object\n","quality_group             object\n","quantity                  object\n","quantity_group            object\n","source                    object\n","source_type               object\n","source_class              object\n","waterpoint_type           object\n","waterpoint_type_group     object\n","status_group              object\n","dtype: object"]},"metadata":{},"execution_count":64}],"source":["df.dtypes"]},{"outputs":[{"output_type":"stream","name":"stderr","text":["[autoreload of features.preprocess failed: Traceback (most recent call last):\n","  File \"/home/nam/Development/anaconda3/envs/water-pumps/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n","    superreload(m, reload, self.old_objects)\n","  File \"/home/nam/Development/anaconda3/envs/water-pumps/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n","    update_generic(old_obj, new_obj)\n","  File \"/home/nam/Development/anaconda3/envs/water-pumps/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n","    update(a, b)\n","  File \"/home/nam/Development/anaconda3/envs/water-pumps/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n","    setattr(old, name, getattr(new, name))\n","ValueError: clean_raw_data() requires a code object with 2 free vars, not 0\n","]\n","The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Change col longitude from 0 to mean\n","Change col latitude from -2e-8 to mean\n","Change col population from 0 to mean\n"]},{"output_type":"error","ename":"AssertionError","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-524e6591118c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# check some actual values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mcleaned_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5.970642969008563\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mcleaned_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m35.14119354200863\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mcleaned_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m277.3070009774711\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: "]}],"source":["%load_ext autoreload\n","%autoreload 1\n","%aimport features.preprocess\n","from features.preprocess import clean_raw_data\n","cleaned_df = clean_raw_data(df)\n","\n","# verify construction year\n","assert (cleaned_df.construction_year > 1000).all()\n","\n","# verify filled in other values\n","for numeric_col in [\"population\", \"longitude\", \"latitude\"]:\n","    assert (cleaned_df[numeric_col] != 0).all()\n","    \n","# verify the types are in the expected types\n","assert (cleaned_df.dtypes\n","                  .astype(str)\n","                  .isin([\"int64\", \"float64\", \"category\"])).all()\n","\n","# check some actual values\n","assert cleaned_df.latitude.mean() == -5.970642969008563\n","assert cleaned_df.longitude.mean() == 35.14119354200863\n","assert cleaned_df.population.mean() == 277.3070009774711"],"execution_count":91,"cell_type":"code","metadata":{"collapsed":false,"scrolled":false}},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0             Iringa\n","1               Mara\n","2            Manyara\n","3             Mtwara\n","4             Kagera\n","            ...     \n","59395    Kilimanjaro\n","59396         Iringa\n","59397          Mbeya\n","59398         Dodoma\n","59399       Morogoro\n","Name: region, Length: 59400, dtype: category\n","Categories (21, object): ['Arusha', 'Dar es Salaam', 'Dodoma', 'Iringa', ..., 'Shinyanga', 'Singida', 'Tabora', 'Tanga']"]},"metadata":{},"execution_count":80}],"source":["cleaned_df.region"]},{"source":["## Exercise 3\n","\n","Now that we've got a feature matrix, let's train a model! Add a function as defined below to the **`src/model/train_model.py`**\n","\n","The function should use [`sklearn.linear_model.LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to train a logistic regression model. In a dataframe with categorical variables `pd.get_dummies` will do encoding that can be passed to `sklearn`.\n","\n","The `LogisticRegression` class in `sklearn` handles muticlass models automatically, so no need to use `get_dummies` on `status_group`.\n","\n","Finally, this method should return a [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) object that has been run with the following parameters for a logistic regression model:\n","\n","    params = {'C': [0.1, 1, 10]}"],"cell_type":"markdown","metadata":{}},{"outputs":[],"source":["def logistic(df):\n","    \"\"\" Trains a multinomial logistic regression model to predict the\n","        status of a water pump given characteristics about the pump.\n","    \n","        :param df: The dataframe with the features and the label.\n","        :returns: A trained GridSearchCV classifier\n","    \"\"\"\n","    pass"],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true}},{"outputs":[],"source":["%%time\n","clf = logistic(cleaned_df)\n","\n","assert clf.best_score_ > 0.5"],"execution_count":null,"cell_type":"code","metadata":{"collapsed":false}},{"outputs":[],"source":["# Just for fun, let's profile the whole stack and see what's slowest!\n","%prun logistic(clean_raw_data(load_pumps_data(values, labels)))"],"execution_count":null,"cell_type":"code","metadata":{"collapsed":false}}],"metadata":{"kernelspec":{"name":"python394jvsc74a57bd00a10f1d30378d8ef0a2d2b8b64cd2741ddd438d5b4e393461420b1b37929d20a","display_name":"Python 3.9.4 64-bit ('water-pumps': conda)"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.9.4-final","pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","mimetype":"text/x-python"}}}